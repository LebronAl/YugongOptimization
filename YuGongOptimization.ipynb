{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "ClusterCapacityInfo : size = 14\n",
      "cluster_name              object\n",
      "cluster_total_cpu        float64\n",
      "cluster_total_storage      int64\n",
      "dtype: object\n",
      "  cluster_name  cluster_total_cpu  cluster_total_storage\n",
      "0        ay75k       6.126449e+11      90889947808845008\n",
      "1        ay75a       4.318640e+11      83102415615917488\n",
      "2        ay98a       9.940431e+11     186109695381537984\n",
      "3        ay49c       4.420882e+12     516597957439482620\n",
      "4        ay75i       1.235933e+12     319121595919632770\n",
      "--------------------\n",
      "TableCpuInfo : size = 1587059\n",
      "project_name       object\n",
      "table_name         object\n",
      "job_count           int64\n",
      "table_cost_cpu    float64\n",
      "dtype: object\n",
      "  project_name                    table_name  job_count  table_cost_cpu\n",
      "0         abif     abc_item_behavior_1_d_001          1          1180.0\n",
      "1         abif  abc_user_behavior_1_d_v2_003        247      29424455.0\n",
      "2         abif  abc_user_behavior_2_d_v2_004        453      84391710.0\n",
      "3         abif  abc_user_behavior_3_d_v2_002        131       4214580.0\n",
      "4         abif  abc_user_behavior_3_d_v2_014         98       1060200.0\n",
      "--------------------\n",
      "TableStorageInfo : size = 1227647\n",
      "project_name     object\n",
      "table_name       object\n",
      "total_storage     int64\n",
      "dtype: object\n",
      "  project_name                            table_name  total_storage\n",
      "0     eleme_ai       cooktime_model_verification_pre   102786857877\n",
      "1     eleme_ai  cooktime_model_verification_realtime    71897386808\n",
      "2     eleme_ai    cooktime_reg_deepfm_model_evaluate   293369396322\n",
      "3     eleme_ai             cooktime_reg_log_data_set   299026551336\n",
      "4     eleme_ai         cooktime_reg_log_features_set   238968539905\n",
      "--------------------\n",
      "TableJobInfo : size = 1708783\n",
      "ndTable            object\n",
      "stTable            object\n",
      "relevence_size    float64\n",
      "dtype: object\n",
      "                             ndTable  \\\n",
      "0  abif.abc_user_behavior_1_d_v2_001   \n",
      "1  abif.abc_user_behavior_1_d_v2_001   \n",
      "2  abif.abc_user_behavior_1_d_v2_001   \n",
      "3  abif.abc_user_behavior_1_d_v2_001   \n",
      "4  abif.abc_user_behavior_1_d_v2_001   \n",
      "\n",
      "                                      stTable  relevence_size  \n",
      "0           abif.abc_user_behavior_2_d_v2_001      553.193410  \n",
      "1        abif.rpt_abif_up_base_asset_d_dsm_v2        9.453107  \n",
      "2                abif.rpt_user_gmv_pub_info_d       18.606075  \n",
      "3            abif.rpt_user_visitor_pub_info_d     3101.123032  \n",
      "4  ysf_pre_compute.fastbit_brand_all_seq_best        0.000005  \n",
      "--------------------\n",
      "TableUpDownInfo : size = 801708\n",
      "output             object\n",
      "input              object\n",
      "relevence_size    float64\n",
      "dtype: object\n",
      "                                              output  \\\n",
      "0            abif.ods_abif_aid_fetched_tags_bus_base   \n",
      "1            abif.ods_abif_aid_fetched_tags_bus_base   \n",
      "2  abif.ods_abif_aid_fetched_tags_bus_homedecoration   \n",
      "3  abif.ods_abif_aid_fetched_tags_bus_homedecoration   \n",
      "4        abif.ods_abif_aid_fetched_tags_bus_homenurs   \n",
      "\n",
      "                                             input  relevence_size  \n",
      "0    abif.ods_abif_aid_fetched_tags_enrich_general       51.774667  \n",
      "1     abif.ods_abif_aid_fetched_tags_enrich_social       51.774667  \n",
      "2  abif.ods_abif_aid_fetched_tags_enrich_commodity        6.323486  \n",
      "3       abif.ods_abif_aid_fetched_tags_enrich_food        6.323486  \n",
      "4       abif.ods_abif_aid_fetched_tags_enrich_home        3.282378  \n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## load data\n",
    "cluster_capacity_df = pd.read_csv('./data/tmp_cluster_20201029', names=['cluster_name', 'cluster_total_cpu', 'cluster_total_storage']).drop_duplicates()\n",
    "table_cpu_cost_df = pd.read_csv('./data/tmp_table_cpu_cost_20201029', names=['project_name','table_name','job_count', 'table_cost_cpu']).drop_duplicates()\n",
    "table_storage_cost_df = pd.read_csv('./data/tmp_table_storage_20201029', names=['project_name', 'table_name', 'total_storage']).drop_duplicates()\n",
    "table_job_df = pd.read_csv('./data/tmp_table_input_relevence_20201029', names=['ndTable', 'stTable', 'relevence_size']).drop_duplicates()\n",
    "table_updown_df = pd.read_csv('./data/tmp_table_output_relevence_20201029', names=['output', 'input', 'relevence_size']).drop_duplicates()\n",
    "\n",
    "## clean data\n",
    "cluster_capacity_df['cluster_name'] = cluster_capacity_df['cluster_name'].str.lower()\n",
    "table_job_df['ndTable'] = table_job_df['ndTable'].str.lower()\n",
    "table_job_df['stTable'] = table_job_df['stTable'].str.lower()\n",
    "table_updown_df['output'] = table_updown_df['output'].str.lower()\n",
    "table_updown_df['input'] = table_updown_df['input'].str.lower()\n",
    "cluster_capacity_df.fillna(value={'cluster_total_cpu':0}, inplace=True)\n",
    "table_cpu_cost_df.fillna(value={'table_cost_cpu':0}, inplace=True)\n",
    "\n",
    "\n",
    "## data info\n",
    "print(\"--------------------\")\n",
    "print(\"ClusterCapacityInfo : size = {}\".format(\n",
    "    cluster_capacity_df.shape[0]))\n",
    "print(cluster_capacity_df.dtypes)\n",
    "print(cluster_capacity_df.head())\n",
    "print(\"--------------------\")\n",
    "print(\"TableCpuInfo : size = {}\".format(table_cpu_cost_df.shape[0]))\n",
    "print(table_cpu_cost_df.dtypes)\n",
    "print(table_cpu_cost_df.head())\n",
    "print(\"--------------------\")\n",
    "print(\"TableStorageInfo : size = {}\".format(table_storage_cost_df.shape[0]))\n",
    "print(table_storage_cost_df.dtypes)\n",
    "print(table_storage_cost_df.head())\n",
    "print(\"--------------------\")\n",
    "print(\"TableJobInfo : size = {}\".format(\n",
    "    table_job_df.shape[0]))\n",
    "print(table_job_df.dtypes)\n",
    "print(table_job_df.head())\n",
    "print(\"--------------------\")\n",
    "print(\"TableUpDownInfo : size = {}\".format(\n",
    "            table_updown_df.shape[0]))\n",
    "print(table_updown_df.dtypes)\n",
    "print(table_updown_df.head())\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 2260/1587059 [00:00<01:10, 22595.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----clusterRouletteProbability----\n",
      "0     0.020064\n",
      "1     0.014143\n",
      "2     0.032554\n",
      "3     0.144780\n",
      "4     0.040476\n",
      "5     0.096798\n",
      "6     0.085117\n",
      "7     0.087404\n",
      "8     0.095132\n",
      "9     0.070813\n",
      "10    0.087447\n",
      "11    0.049736\n",
      "12    0.041575\n",
      "13    0.133961\n",
      "Name: cluster_total_cpu, dtype: float64\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1587059/1587059 [01:10<00:00, 22651.50it/s]\n",
      "Processing: 100%|██████████| 1708783/1708783 [00:36<00:00, 47176.87it/s]\n",
      "Processing: 100%|██████████| 801708/801708 [00:17<00:00, 47009.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----totalFlow----\n",
      "305053213.15901905\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "table_size = table_cpu_cost_df.shape[0]\n",
    "cluster_size = cluster_capacity_df.shape[0]\n",
    "table_job_size = table_job_df.shape[0]\n",
    "table_updown_size = table_updown_df.shape[0]\n",
    "\n",
    "## get Cluster Probability during choosing cluster based on this total cpu\n",
    "clusterRouletteProbability = cluster_capacity_df['cluster_total_cpu'] / cluster_capacity_df['cluster_total_cpu'].sum()\n",
    "print('----clusterRouletteProbability----')\n",
    "print(clusterRouletteProbability)\n",
    "print('--------')\n",
    "\n",
    "\n",
    "## inverted index from table to their index\n",
    "table2index = {}\n",
    "for index in tqdm(range(table_size), desc='Processing'):\n",
    "    table2index[table_cpu_cost_df.iloc[index, 0] + '.' + table_cpu_cost_df.iloc[index, 1]] = index\n",
    "\n",
    "## get total Flow\n",
    "totalFlow = 0\n",
    "for index in tqdm(range(table_job_size), desc='Processing'):\n",
    "    totalFlow += table_job_df.iloc[index, 2]    \n",
    "for index in tqdm(range(table_updown_size), desc='Processing'):\n",
    "    totalFlow += table_updown_df.iloc[index, 2]\n",
    "\n",
    "print('----totalFlow----')\n",
    "print(totalFlow)\n",
    "print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "## evalute roulette Random algorithm\n",
    "def rouletteRandom(probability):\n",
    "    sum = 0\n",
    "    ran = random.random()\n",
    "    for num, r in zip(range(len(probability)), probability):\n",
    "        sum += r\n",
    "        if ran < sum :\n",
    "            break\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each individual, we calculate it's assessment, which is innerFlow and innerFlow.\n",
    "## Addition, we stores the usedCPUMap(key=cluster_index,value=totalCPUForThisPlancement) and clusterTableMap(key=cluster_index,value=list(table_index))\n",
    "class Individual:\n",
    "    \n",
    "    def __init__(self, entity, usedCPUMap, clusterTableMap, execute):\n",
    "        self.entity = entity\n",
    "        self.innerFlow = 0;\n",
    "        self.crossFlow = 0\n",
    "        self.usedCPUMap = usedCPUMap\n",
    "        self.clusterTableMap = clusterTableMap\n",
    "        if execute:\n",
    "            self.figureAssessment()\n",
    "        \n",
    "    def figureAssessment(self):\n",
    "        self.figureTableJob()\n",
    "        self.figureTableUpdown()\n",
    "        self.printInfo()\n",
    "        \n",
    "    def printInfo(self):\n",
    "        print(\"----IndividualInfo----\")\n",
    "        print(\"InnerFlow: \" + str(self.innerFlow))\n",
    "        print(\"CrossFlow: \" + str(self.crossFlow))\n",
    "        print(\"CPUUsage: \")\n",
    "        for index in range(len(self.usedCPUMap)):\n",
    "            print(str(index) + \":\" + str(self.usedCPUMap[index] / cluster_capacity_df.iloc[index, 1]))\n",
    "        print(\"--------\")\n",
    "        \n",
    "    def figureTableJob(self):\n",
    "        for index in range(table_job_size):\n",
    "            if table_job_df.iloc[index, 0] in table2index.keys():\n",
    "                left = table2index[table_job_df.iloc[index, 0]]\n",
    "            else:\n",
    "                continue\n",
    "            if table_job_df.iloc[index, 1] in table2index.keys():\n",
    "                right = table2index[table_job_df.iloc[index, 1]]\n",
    "            else:\n",
    "                continue\n",
    "            if self.entity[left] != self.entity[right]:\n",
    "                self.crossFlow += table_job_df.iloc[index, 2]\n",
    "            else:\n",
    "                self.innerFlow += table_job_df.iloc[index, 2]\n",
    "        \n",
    "    def figureTableUpdown(self):\n",
    "        for index in range(table_updown_size):\n",
    "            if table_updown_df.iloc[index, 0] in table2index.keys():\n",
    "                left = table2index[table_updown_df.iloc[index, 0]]\n",
    "            else:\n",
    "                continue\n",
    "            if table_updown_df.iloc[index, 1] in table2index.keys():\n",
    "                right = table2index[table_updown_df.iloc[index, 1]]\n",
    "            else:\n",
    "                continue\n",
    "            if self.entity[left] != self.entity[right]:\n",
    "                self.crossFlow += table_job_df.iloc[index, 2]\n",
    "            else:\n",
    "                self.innerFlow += table_job_df.iloc[index, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random generates a valid ndividual along with it's usedCPUMap and clusterTableMap\n",
    "def figureInitPopulation():\n",
    "    usedCPUMap = np.zeros([cluster_size], dtype = np.int64)\n",
    "    clusterTableMap = {}\n",
    "    entity = np.zeros([table_size], dtype = np.int8)\n",
    "    for index in tqdm(range(table_size), desc='Processing'):\n",
    "        while True:\n",
    "            choosedCluster = rouletteRandom(clusterRouletteProbability)\n",
    "            if usedCPUMap[choosedCluster] + table_cpu_cost_df.iloc[index, 3] <= cluster_capacity_df.iloc[choosedCluster, 1]:\n",
    "                usedCPUMap[choosedCluster] += table_cpu_cost_df.iloc[index, 3]\n",
    "                if choosedCluster not in clusterTableMap.keys():\n",
    "                    clusterTableMap[choosedCluster] = []\n",
    "                clusterTableMap[choosedCluster].append(index)\n",
    "                entity[index] = choosedCluster\n",
    "                break\n",
    "    return Individual(entity, usedCPUMap, clusterTableMap, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1587059/1587059 [04:06<00:00, 6432.41it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:07<00:00, 6417.31it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:07<00:00, 6416.14it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:07<00:00, 6404.45it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:07<00:00, 6404.53it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:07<00:00, 6403.62it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:08<00:00, 6398.36it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:08<00:00, 6387.65it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:09<00:00, 6372.28it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:09<00:00, 6365.17it/s]\n",
      "Processing: 100%|██████████| 1587059/1587059 [04:09<00:00, 6362.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----IndividualInfo----\n",
      "InnerFlow: 6631745.745196534\n",
      "CrossFlow: 64285963.040695064\n",
      "CPUUsage: \n",
      "0:0.9308601534522722\n",
      "1:0.7759400640483624\n",
      "2:0.827718805884811\n",
      "3:0.7353533877669575\n",
      "4:0.6667907020876743\n",
      "5:0.769346210905032\n",
      "6:0.7278863274636168\n",
      "7:0.6408767819497337\n",
      "8:0.8045350469679611\n",
      "9:0.5635677160293014\n",
      "10:0.6364328998556473\n",
      "11:0.8132625834024327\n",
      "12:0.8669729884273214\n",
      "13:0.8584904782859965\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 8213191.457417835\n",
      "CrossFlow: 62704517.3284736\n",
      "CPUUsage: \n",
      "0:0.5959155451726074\n",
      "1:0.730533113385975\n",
      "2:0.6448135245785184\n",
      "3:0.826951039745757\n",
      "4:0.7796576661139895\n",
      "5:0.7498311396943466\n",
      "6:0.6194145090120358\n",
      "7:0.7489699243138668\n",
      "8:0.70334494841168\n",
      "9:0.5876522729591453\n",
      "10:0.601485913208933\n",
      "11:0.9999999999972106\n",
      "12:0.8989794500619384\n",
      "13:0.8399757514462934\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 7011786.8061866565\n",
      "CrossFlow: 63905921.979704194\n",
      "CPUUsage: \n",
      "0:0.8226781082364479\n",
      "1:0.6245271680522638\n",
      "2:0.5364763258994071\n",
      "3:0.717018423342744\n",
      "4:0.7538592645862471\n",
      "5:0.7022472330094262\n",
      "6:0.7853488554221106\n",
      "7:0.7090708805341885\n",
      "8:0.892698152559683\n",
      "9:0.9999999999706959\n",
      "10:0.7120538453545197\n",
      "11:0.5827223649380725\n",
      "12:0.6633742457785402\n",
      "13:0.7285472212002956\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 6688048.253361636\n",
      "CrossFlow: 64229660.53252989\n",
      "CPUUsage: \n",
      "0:0.7907837260790179\n",
      "1:0.7072903841315265\n",
      "2:0.5424419705463435\n",
      "3:0.6338576120031513\n",
      "4:0.6449510399079953\n",
      "5:0.7989450105162363\n",
      "6:0.9829685606928754\n",
      "7:0.8041694276063773\n",
      "8:0.7565629620498795\n",
      "9:0.6516673928231347\n",
      "10:0.8411739587213013\n",
      "11:0.7567406947617622\n",
      "12:0.7485195095759195\n",
      "13:0.6939215464256454\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 8272893.794166384\n",
      "CrossFlow: 62644814.99172506\n",
      "CPUUsage: \n",
      "0:0.8093185028663755\n",
      "1:0.8132350794557333\n",
      "2:0.6362061306902158\n",
      "3:0.9034130264261205\n",
      "4:0.6750023217488477\n",
      "5:0.6736096550689209\n",
      "6:0.7339179485237446\n",
      "7:0.8322301418016176\n",
      "8:0.7639916582280787\n",
      "9:0.746629078327395\n",
      "10:0.7804592729483043\n",
      "11:0.6525063401714736\n",
      "12:0.5955332228871576\n",
      "13:0.6576107573055896\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 8020651.1464154925\n",
      "CrossFlow: 62897057.63947507\n",
      "CPUUsage: \n",
      "0:0.7145992943766988\n",
      "1:0.5057403155614638\n",
      "2:0.6725905583526257\n",
      "3:0.7539852915047436\n",
      "4:0.6175984961877286\n",
      "5:0.955512004742145\n",
      "6:0.8013011911346586\n",
      "7:0.6404422828664255\n",
      "8:0.8409998640520691\n",
      "9:0.8279792625692161\n",
      "10:0.7087176974019492\n",
      "11:0.7208811671559785\n",
      "12:0.6304873279775371\n",
      "13:0.6657875998101493\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 7361682.016816056\n",
      "CrossFlow: 63556026.76907468\n",
      "CPUUsage: \n",
      "0:0.6266746713097449\n",
      "1:0.9999999999179033\n",
      "2:0.7525053167895136\n",
      "3:0.9244592492057284\n",
      "4:0.7659891646730959\n",
      "5:0.7514778521813525\n",
      "6:0.8238275363898901\n",
      "7:0.5644805627799252\n",
      "8:0.6172051128701258\n",
      "9:0.6214851395396052\n",
      "10:0.8870680709233013\n",
      "11:0.693231598173745\n",
      "12:0.7320474831665591\n",
      "13:0.6913623669592751\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 7172142.837656181\n",
      "CrossFlow: 63745565.94823513\n",
      "CPUUsage: \n",
      "0:0.5561729744312545\n",
      "1:0.614910419357292\n",
      "2:0.8396723590721024\n",
      "3:0.6452730241744313\n",
      "4:0.8121555298517349\n",
      "5:0.7257225617347559\n",
      "6:0.7134308093780706\n",
      "7:0.799975125330749\n",
      "8:0.8160108143112549\n",
      "9:0.7997372199540367\n",
      "10:0.9120316451778169\n",
      "11:0.6307458722383218\n",
      "12:0.853456387318713\n",
      "13:0.6781011889822451\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 7195585.112941933\n",
      "CrossFlow: 63722123.67294927\n",
      "CPUUsage: \n",
      "0:0.6694045526416624\n",
      "1:0.607591019010197\n",
      "2:0.807630838427684\n",
      "3:0.73723417281106\n",
      "4:0.7039878445368015\n",
      "5:0.8941971243000657\n",
      "6:0.9999999999939139\n",
      "7:0.8071324936020488\n",
      "8:0.6048801629268947\n",
      "9:0.6611381099048298\n",
      "10:0.7409771069802019\n",
      "11:0.672459072762475\n",
      "12:0.7716569048395633\n",
      "13:0.6392656395877641\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 7048042.974298042\n",
      "CrossFlow: 63869665.811593115\n",
      "CPUUsage: \n",
      "0:0.6052853915021162\n",
      "1:0.972739118972977\n",
      "2:0.6962630417052088\n",
      "3:0.7174793926962848\n",
      "4:0.6553514861718328\n",
      "5:0.7066492122743288\n",
      "6:0.92902102970062\n",
      "7:0.623832961397141\n",
      "8:0.7138417368065709\n",
      "9:0.775911258247273\n",
      "10:0.7703141991351633\n",
      "11:0.7666477133657217\n",
      "12:0.7686480033654698\n",
      "13:0.7824052589826763\n",
      "--------\n",
      "----IndividualInfo----\n",
      "InnerFlow: 7487444.023277558\n",
      "CrossFlow: 63430264.76261321\n",
      "CPUUsage: \n",
      "0:0.792448351506552\n",
      "1:0.6533832248595833\n",
      "2:0.7289213291133618\n",
      "3:0.616193890899363\n",
      "4:0.6377627989058487\n",
      "5:0.720159331007468\n",
      "6:0.6215309722082967\n",
      "7:0.6908299553192534\n",
      "8:0.8276775649646217\n",
      "9:0.703004848795636\n",
      "10:0.8740739392644664\n",
      "11:0.7560805257375034\n",
      "12:0.9081051352408769\n",
      "13:0.8874426253923242\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "## init cpu_num - 1 individuals for first population using alomost all cpu process to accelerate \n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "population = []\n",
    "population_size = multiprocessing.cpu_count() - 1\n",
    "\n",
    "results = []\n",
    "pool = multiprocessing.Pool(population_size)\n",
    "\n",
    "for i in range(population_size):\n",
    "    results.append(pool.apply_async(func=figureInitPopulation))\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "for result in results:\n",
    "    population.append(result.get())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select two individuals for population based on their assessment and probability\n",
    "def selection(population):\n",
    "    sum = 0\n",
    "    populationProbability = []\n",
    "    for individual in population:\n",
    "        sum += individual.innerFlow\n",
    "    for individual in population:\n",
    "        populationProbability.append(individual.innerFlow / sum)\n",
    "    individual_1 = rouletteRandom(populationProbability)\n",
    "    individual_2 = rouletteRandom(populationProbability)\n",
    "    while individual_1 == individual_2:\n",
    "            individual_2 = rouletteRandom(populationProbability)\n",
    "    return individual_1, individual_2\n",
    "\n",
    "## generate one individuals base on their parents to store good gene\n",
    "def crossover(individual_1, individual_2):\n",
    "    stage = 1000\n",
    "    entity = np.zeros([table_size], dtype = np.int8)\n",
    "    usedCPUMap = np.zeros([cluster_size], dtype = np.int64)\n",
    "    clusterTableMap = {}\n",
    "    for index in range(table_size):\n",
    "        if index % stage == 0:\n",
    "            if index + stage <= table_size:\n",
    "                end = index + stage\n",
    "            else:\n",
    "                end = table_size\n",
    "            if random.randint(0,1) == 0:\n",
    "                for i in range(index, end):\n",
    "                    entity[i] = population[individual_1].entity[i]\n",
    "            else:\n",
    "                for i in range(index, end):\n",
    "                    entity[i] = population[individual_2].entity[i]\n",
    "        usedCPUMap[entity[index]] += table_cpu_cost_df.iloc[index, 3]\n",
    "        if entity[index] not in clusterTableMap.keys():\n",
    "            clusterTableMap[entity[index]] = []\n",
    "        clusterTableMap[entity[index]].append(index)\n",
    "    return Individual(entity, usedCPUMap, clusterTableMap, False)\n",
    "\n",
    "## mutate this individuals to extent search space\n",
    "def mutate(individual):\n",
    "    mutateProbability = 0.001\n",
    "    num = int(table_size * mutateProbability)\n",
    "    for _ in range(num):\n",
    "        chooseTable = random.randint(0, table_size)\n",
    "        newCluster = rouletteRandom(clusterRouletteProbability)\n",
    "        if newCluster != individual.entity[chooseTable]:\n",
    "            individual.usedCPUMap[individual.entity[chooseTable]] -= table_cpu_cost_df.iloc[chooseTable, 3]\n",
    "            individual.usedCPUMap[newCluster] += table_cpu_cost_df.iloc[chooseTable, 3]\n",
    "            individual.clusterTableMap[individual.entity[chooseTable]].remove(chooseTable)\n",
    "            individual.clusterTableMap[newCluster].append(chooseTable)\n",
    "            individual.entity[chooseTable] = newCluster\n",
    "            \n",
    "\n",
    "## repair this individual to make it feasible after crossover and mutate\n",
    "def repair(individual):\n",
    "    while True:\n",
    "        valid = True\n",
    "        for index in range(cluster_size):\n",
    "            while individual.usedCPUMap[index] > cluster_capacity_df.iloc[index, 1]:\n",
    "                valid = False\n",
    "                chooseTable = random.choice(individual.clusterTableMap[index])\n",
    "                newCluster = rouletteRandom(clusterRouletteProbability)\n",
    "                if newCluster != individual.entity[chooseTable]:\n",
    "                    individual.usedCPUMap[individual.entity[chooseTable]] -= table_cpu_cost_df.iloc[chooseTable, 3]\n",
    "                    individual.usedCPUMap[newCluster] += table_cpu_cost_df.iloc[chooseTable, 3]\n",
    "                    individual.clusterTableMap[individual.entity[chooseTable]].remove(chooseTable)\n",
    "                    individual.clusterTableMap[newCluster].append(chooseTable)\n",
    "                    individual.entity[chooseTable] = newCluster\n",
    "        if valid:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate a feasible individual base on parent population\n",
    "def run():\n",
    "    individual_1, individual_2 = selection(population)\n",
    "    individual = crossover(individual_1,individual_2)\n",
    "    mutate(individual)\n",
    "    repair(individual)\n",
    "    individual.figureAssessment()\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "breeding_rate = multiprocessing.cpu_count() - 1\n",
    "# one for 7 minutes\n",
    "iterations = 200\n",
    "minCrossFlows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "## perform <iterations> iterations\n",
    "## generation <breeding_rate> individuals for each iteration using <breeding_rate> process to accelerate \n",
    "    \n",
    "import os\n",
    "\n",
    "for times in tqdm(range(iterations), desc='Processing'):\n",
    "    results = []\n",
    "    pool = multiprocessing.Pool(breeding_rate)\n",
    "\n",
    "    for i in range(breeding_rate):\n",
    "        results.append(pool.apply_async(func=run))\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    for result in results:\n",
    "        population.append(result.get())\n",
    "        \n",
    "    minInnerFlow = population[0].innerFlow\n",
    "    minInnerFlowIndex = 0;\n",
    "    minCrossFlow = population[0].crossFlow\n",
    "    while len(population) > population_size:\n",
    "        minInnerFlow = population[0].innerFlow\n",
    "        minInnerFlowIndex = 0;\n",
    "        for index in range(len(population)):\n",
    "            if population[index].innerFlow < minInnerFlow:\n",
    "                minInnerFlowIndex = index\n",
    "            if population[index].crossFlow < minCrossFlow:\n",
    "                minCrossFlow = population[index].crossFlow\n",
    "        del population[minInnerFlowIndex]\n",
    "    \n",
    "    minCrossFlows.append(minCrossFlow)\n",
    "    print(\"----\" + str(times + 1) + \" iteration----\")\n",
    "    print(\"minCrossFlow: \" +  str(minCrossFlow))\n",
    "    print(\"CrossFlows: \")\n",
    "    for i in population:\n",
    "        print(i.crossFlow)\n",
    "    print(\"--------\")\n",
    "    \n",
    "    isExists= os.path.exists(\"./placement\")\n",
    "    if not isExists:\n",
    "        os.mkdir(\"./placement\")\n",
    "    for index in range(len(population)):\n",
    "        pickle.dump(population[index], open(\"./placement/data\" + str(index), 'wb'))\n",
    "\n",
    "    pickle.dump(minCrossFlows,open(\"./placement/flows\", 'wb'))\n",
    "    \n",
    "print(\"----itertions for minCrossFlow----\")\n",
    "print(minCrossFlows)\n",
    "print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pickle.load(open(\"./placement/data\" + str(0),'rb'))\n",
    "first.entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = pickle.load(open(\"./placement/flows\",'rb'))\n",
    "flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
